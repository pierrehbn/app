import streamlit as st
from duckduckgo_search import ddg
import requests
from bs4 import BeautifulSoup
import pandas as pd

st.set_page_config(page_title="Radar Immo - Li√®ge", layout="wide")
st.title("üè† Radar Immo : Embourg ¬∑ Beaufays ¬∑ Chaudfontaine")

sources = [
    "immoweb.be",
    "immovlan.be"
]

zones = ["Embourg", "Beaufays", "Chaudfontaine"]

def enrich(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(res.text, 'html.parser')

        title = soup.find("meta", property="og:title")
        full_text = soup.get_text(separator=' ')
        price_match = ""
        address_match = ""

        for line in full_text.splitlines():
            if "‚Ç¨" in line and any(x in line.lower() for x in ["prix", "‚Ç¨"]):
                price_match = line.strip()
                break

        for line in full_text.splitlines():
            if any(zone in line for zone in zones):
                address_match = line.strip()
                break

        return {
            "Titre": title["content"] if title else "Sans titre",
            "Prix": price_match or "Non d√©tect√©",
            "Adresse": address_match or "Non trouv√©e",
            "Lien": url
        }

    except Exception as e:
        return {
            "Titre": "Erreur",
            "Prix": "‚Äî",
            "Adresse": "‚Äî",
            "Lien": url
        }

def search_duckduckgo(query, max_results=3):
    try:
        results = ddg(query, max_results=max_results)
        return [r['href'] for r in results if 'href' in r]
    except Exception as e:
        print(f"Erreur DuckDuckGo pour '{query}':", e)
        return []

if st.button("üîç Lancer la recherche"):
    all_results = []
    with st.spinner("Recherche en cours..."):
        for zone in zones:
            for source in sources:
                query = f"site:{source} maison √† vendre {zone}"
                urls = search_duckduckgo(query, max_results=3)
                for url in urls:
                    enriched = enrich(url)
                    all_results.append(enriched)
    df = pd.DataFrame(all_results)
    st.dataframe(df, use_container_width=True)
